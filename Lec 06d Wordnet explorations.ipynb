{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLsxYIoRQP7e"
   },
   "source": [
    "# Intro to Wordnet functionality\n",
    "\n",
    "While local context means a lot in understanding the meanings of words in a corpus, words also have ‘global’ commonly-known context-free meanings as well.\n",
    "\n",
    "For instance, if we were to hear the adjective “great” without knowing the context, we would assume some meaning for it (i.e. context-free meaning is assigned). \n",
    "\n",
    "A reporsitory for such meanings (and other semantic manipulations) of words is a dictionary.\n",
    "\n",
    "Imagine we could access and query an English dictionary at will inside py. \n",
    "\n",
    "We could apply the dictionary to text patterns we see in the corpus in order to obtain greater meaning.\n",
    "\n",
    "In what follows, we will query Princeton’s wordnet dictionary database from inside py via NLTK and then, spaCy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oc5Ht6oERJZa"
   },
   "source": [
    "### Setup Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "mJByKV9fQeOD",
    "outputId": "6cb17989-32ca-4ac1-c13c-fc17f4a10747"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\31202\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "_OxT6sTgQGAv",
    "outputId": "f702efbf-391b-4d6f-a899-49851df27f1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonyms of good are:\n",
      " ['good', 'good', 'goodness', 'good', 'goodness', 'commodity', 'trade_good', 'good', 'good', 'full', 'good', 'good', 'estimable', 'good', 'honorable', 'respectable', 'beneficial', 'good', 'good', 'good', 'just', 'upright', 'adept', 'expert', 'good', 'practiced', 'proficient', 'skillful', 'skilful', 'good', 'dear', 'good', 'near', 'dependable', 'good', 'safe', 'secure', 'good', 'right', 'ripe', 'good', 'well', 'effective', 'good', 'in_effect', 'in_force', 'good', 'good', 'serious', 'good', 'sound', 'good', 'salutary', 'good', 'honest', 'good', 'undecomposed', 'unspoiled', 'unspoilt', 'good', 'well', 'good', 'thoroughly', 'soundly', 'good']\n",
      "==================== \n",
      "\n",
      "antonyms of good are:\n",
      " ['evil', 'evilness', 'bad', 'badness', 'bad', 'evil', 'ill']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn  # how to d/l wordnet in jupy or colab?\n",
    "\n",
    "# querying for simple synonyms and antonyms\n",
    "antonyms=[]\n",
    "synonyms=[]\n",
    "for syn in wn.synsets(\"good\"): \n",
    "    for l in syn.lemmas(): \n",
    "        synonyms.append(l.name()) \n",
    "        if l.antonyms(): \n",
    "            antonyms.append(l.antonyms()[0].name()) \n",
    "\n",
    "print(\"synonyms of good are:\\n\", synonyms)\n",
    "print(\"=\"*20, \"\\n\")\n",
    "print(\"antonyms of good are:\\n\", antonyms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xGtQ84IQNc4"
   },
   "source": [
    "### Intro to synsets\n",
    "\n",
    "Synsets or synonym sets are the basic unit of wordnet queries. \n",
    "\n",
    "A synset as the name suggests constructs a set of synonyms for different forms and contexts in which a word may occur.\n",
    "\n",
    "Below, we see 5 different contexts or word forms for 'car' in Eng as per wordnet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "SroldcBlQv8n",
    "outputId": "970e1143-0024-4a9c-a43f-c6a04cf6c6e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01'),\n",
       " Synset('car.n.02'),\n",
       " Synset('car.n.03'),\n",
       " Synset('car.n.04'),\n",
       " Synset('cable_car.n.01')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find synsets for the word 'car'\n",
    "car_synsets = wn.synsets('car')\n",
    "car_synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KS2RPhflQ7Or"
   },
   "source": [
    "There's more that can be done in NLP with query-able dictionaries at our fingertips.\n",
    "\n",
    "For instance we could dig deep to find out the lemma of every different context in which the word (say, 'car') appears.\n",
    "\n",
    "Or find the more abstract or general form ('Hypernym') of a word (e.g., car --> vehicle or automobile).\n",
    "\n",
    "Or the more specific form of the word i.e. Hyponym (e.g. 'car' -> 'cable car', 'rail car' etc.)\n",
    "\n",
    "Or find the POStag etc. Behold below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MbPMzQVUQ0-q"
   },
   "outputs": [],
   "source": [
    "# empty lists to populate\n",
    "synset_id=[]; lemma=[]; defn=[]; example=[]; \n",
    "hypernyms=[]; hyponyms=[]; root_hypernym=[]; pos=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUQrbpBARCAG"
   },
   "outputs": [],
   "source": [
    "# loop over every synset for every form of car in wqordnet\n",
    "for i in range( len(car_synsets)):\n",
    "    car = car_synsets[i]; car\n",
    "    synset_id.append(car)\n",
    "    lemma.append(str(car.lemmas()))\n",
    "    defn.append(str(car.definition()))\n",
    "    example.append(str(car.examples()))\n",
    "    hypernyms.append(str(car.hypernyms()))\n",
    "    hyponyms.append(str(car.hyponyms()))\n",
    "    root_hypernym.append(str(car.root_hypernyms()))\n",
    "    pos.append(str(car.pos()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvtELQ9xREVr"
   },
   "outputs": [],
   "source": [
    "# store in DF for good display    \n",
    "wn_df = pd.DataFrame({'synset_id':synset_id, 'lemma':lemma, 'defn':defn, \n",
    "                      'example':example, 'hypernyms':hypernyms, 'hyponyms':hyponyms,\n",
    "                      'root_hypernym':root_hypernym, 'pos':pos})    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "bwCYWRnIRHEH",
    "outputId": "48dfe293-c55f-42e5-b71b-eebbb2b58a0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>synset_id</th>\n",
       "      <td>Synset('car.n.01')</td>\n",
       "      <td>Synset('car.n.02')</td>\n",
       "      <td>Synset('car.n.03')</td>\n",
       "      <td>Synset('car.n.04')</td>\n",
       "      <td>Synset('cable_car.n.01')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lemma</th>\n",
       "      <td>[Lemma('car.n.01.car'), Lemma('car.n.01.auto')...</td>\n",
       "      <td>[Lemma('car.n.02.car'), Lemma('car.n.02.railca...</td>\n",
       "      <td>[Lemma('car.n.03.car'), Lemma('car.n.03.gondol...</td>\n",
       "      <td>[Lemma('car.n.04.car'), Lemma('car.n.04.elevat...</td>\n",
       "      <td>[Lemma('cable_car.n.01.cable_car'), Lemma('cab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>defn</th>\n",
       "      <td>a motor vehicle with four wheels; usually prop...</td>\n",
       "      <td>a wheeled vehicle adapted to the rails of rail...</td>\n",
       "      <td>the compartment that is suspended from an airs...</td>\n",
       "      <td>where passengers ride up and down</td>\n",
       "      <td>a conveyance for passengers or freight on a ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <td>['he needs a car to get to work']</td>\n",
       "      <td>['three cars had jumped the rails']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['the car was on the top floor']</td>\n",
       "      <td>['they took a cable car to the top of the moun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypernyms</th>\n",
       "      <td>[Synset('motor_vehicle.n.01')]</td>\n",
       "      <td>[Synset('wheeled_vehicle.n.01')]</td>\n",
       "      <td>[Synset('compartment.n.02')]</td>\n",
       "      <td>[Synset('compartment.n.02')]</td>\n",
       "      <td>[Synset('compartment.n.02')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyponyms</th>\n",
       "      <td>[Synset('ambulance.n.01'), Synset('beach_wagon...</td>\n",
       "      <td>[Synset('baggage_car.n.01'), Synset('cabin_car...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_hypernym</th>\n",
       "      <td>[Synset('entity.n.01')]</td>\n",
       "      <td>[Synset('entity.n.01')]</td>\n",
       "      <td>[Synset('entity.n.01')]</td>\n",
       "      <td>[Synset('entity.n.01')]</td>\n",
       "      <td>[Synset('entity.n.01')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               0  \\\n",
       "synset_id                                     Synset('car.n.01')   \n",
       "lemma          [Lemma('car.n.01.car'), Lemma('car.n.01.auto')...   \n",
       "defn           a motor vehicle with four wheels; usually prop...   \n",
       "example                        ['he needs a car to get to work']   \n",
       "hypernyms                         [Synset('motor_vehicle.n.01')]   \n",
       "hyponyms       [Synset('ambulance.n.01'), Synset('beach_wagon...   \n",
       "root_hypernym                            [Synset('entity.n.01')]   \n",
       "pos                                                            n   \n",
       "\n",
       "                                                               1  \\\n",
       "synset_id                                     Synset('car.n.02')   \n",
       "lemma          [Lemma('car.n.02.car'), Lemma('car.n.02.railca...   \n",
       "defn           a wheeled vehicle adapted to the rails of rail...   \n",
       "example                      ['three cars had jumped the rails']   \n",
       "hypernyms                       [Synset('wheeled_vehicle.n.01')]   \n",
       "hyponyms       [Synset('baggage_car.n.01'), Synset('cabin_car...   \n",
       "root_hypernym                            [Synset('entity.n.01')]   \n",
       "pos                                                            n   \n",
       "\n",
       "                                                               2  \\\n",
       "synset_id                                     Synset('car.n.03')   \n",
       "lemma          [Lemma('car.n.03.car'), Lemma('car.n.03.gondol...   \n",
       "defn           the compartment that is suspended from an airs...   \n",
       "example                                                       []   \n",
       "hypernyms                           [Synset('compartment.n.02')]   \n",
       "hyponyms                                                      []   \n",
       "root_hypernym                            [Synset('entity.n.01')]   \n",
       "pos                                                            n   \n",
       "\n",
       "                                                               3  \\\n",
       "synset_id                                     Synset('car.n.04')   \n",
       "lemma          [Lemma('car.n.04.car'), Lemma('car.n.04.elevat...   \n",
       "defn                           where passengers ride up and down   \n",
       "example                         ['the car was on the top floor']   \n",
       "hypernyms                           [Synset('compartment.n.02')]   \n",
       "hyponyms                                                      []   \n",
       "root_hypernym                            [Synset('entity.n.01')]   \n",
       "pos                                                            n   \n",
       "\n",
       "                                                               4  \n",
       "synset_id                               Synset('cable_car.n.01')  \n",
       "lemma          [Lemma('cable_car.n.01.cable_car'), Lemma('cab...  \n",
       "defn           a conveyance for passengers or freight on a ca...  \n",
       "example        ['they took a cable car to the top of the moun...  \n",
       "hypernyms                           [Synset('compartment.n.02')]  \n",
       "hyponyms                                                      []  \n",
       "root_hypernym                            [Synset('entity.n.01')]  \n",
       "pos                                                            n  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display results\n",
    "print(wn_df.shape)  # more colms than rows.\n",
    "wn_df.T  # hence displaying transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JOdn4W8sRqC7"
   },
   "source": [
    "One way to incorporate context around words is to specify domain in which word was invoked. \n",
    "\n",
    "E.g., 'bank' can refer to a business, a river, a road etc., which come from domains \"business\", \"geography\", \"construction\" etc.\n",
    "\n",
    "There is a pre-defined long list of domains which we can invoke and check for. See below for 'price'.\n",
    "\n",
    "We do this in spaCy, so setup follows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8D17YeJmRw50"
   },
   "source": [
    "### Setup Chunk for Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "id": "B09MKE2HRW-7",
    "outputId": "6ad04962-bffd-4c68-d044-b3072b43e9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy-wordnet\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/f2/4d8070df0f7a7a9eeed74eb7e9ce3cf41349eb5e06b1e088de9eeca630e2/spacy-wordnet-0.0.4.tar.gz (648kB)\n",
      "Collecting nltk<3.4,>=3.3\n",
      "  Downloading https://files.pythonhosted.org/packages/50/09/3b1755d528ad9156ee7243d52aa5cd2b809ef053a0f31b53d92853dd653a/nltk-3.3.0.zip (1.4MB)\n",
      "Requirement already satisfied: six in c:\\users\\31202\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from nltk<3.4,>=3.3->spacy-wordnet) (1.13.0)\n",
      "Building wheels for collected packages: spacy-wordnet, nltk\n",
      "  Building wheel for spacy-wordnet (setup.py): started\n",
      "  Building wheel for spacy-wordnet (setup.py): finished with status 'done'\n",
      "  Created wheel for spacy-wordnet: filename=spacy_wordnet-0.0.4-py2.py3-none-any.whl size=650298 sha256=15676a36cc8c4ba4ffe6cd3e598d574fd70bfea87b7c4d3dc2ff02f42a3c517e\n",
      "  Stored in directory: C:\\Users\\31202\\AppData\\Local\\pip\\Cache\\wheels\\25\\93\\1d\\c86db913cd146fc9ddb26d10f56579c5d58a3e00bc8f96a3a6\n",
      "  Building wheel for nltk (setup.py): started\n",
      "  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.3-cp37-none-any.whl size=1394477 sha256=26f5f9af9d191ec218be2afb4efd92b3f018f986757bdf41e480edf6eb747d1f\n",
      "  Stored in directory: C:\\Users\\31202\\AppData\\Local\\pip\\Cache\\wheels\\d1\\ab\\40\\3bceea46922767e42986aef7606a600538ca80de6062dc266c\n",
      "Successfully built spacy-wordnet nltk\n",
      "Installing collected packages: nltk, spacy-wordnet\n",
      "  Found existing installation: nltk 3.4.5\n",
      "    Uninstalling nltk-3.4.5:\n",
      "      Successfully uninstalled nltk-3.4.5\n",
      "Successfully installed nltk-3.3 spacy-wordnet-0.0.4\n",
      "Collecting py_thesaurus\n",
      "  Downloading https://files.pythonhosted.org/packages/11/82/56dab6aa24852367b43913e91990c562db49d9b05fc373531fe268fe3525/py_thesaurus-1.0.5.tar.gz\n",
      "Requirement already satisfied: lxml in c:\\users\\31202\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from py_thesaurus) (4.4.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\31202\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from py_thesaurus) (4.8.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\31202\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from beautifulsoup4->py_thesaurus) (1.9.5)\n",
      "Building wheels for collected packages: py-thesaurus\n",
      "  Building wheel for py-thesaurus (setup.py): started\n",
      "  Building wheel for py-thesaurus (setup.py): finished with status 'done'\n",
      "  Created wheel for py-thesaurus: filename=py_thesaurus-1.0.5-cp37-none-any.whl size=6275 sha256=52edf617ee428b9d4bfe217bc4cbe465fc876447e4846fb6595d92dc3d07c405\n",
      "  Stored in directory: C:\\Users\\31202\\AppData\\Local\\pip\\Cache\\wheels\\a6\\c1\\5a\\124ea0abccb2ed21abcea99f376cd37d4dc99c8aa515a471f1\n",
      "Successfully built py-thesaurus\n",
      "Installing collected packages: py-thesaurus\n",
      "Successfully installed py-thesaurus-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy-wordnet\n",
    "!pip install py_thesaurus\n",
    "\n",
    "import spacy\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LwidzrvLR1Ul"
   },
   "outputs": [],
   "source": [
    "# Load an spacy model (supported models are \"es\" and \"en\")\n",
    "# nlp = spacy.load('en')\n",
    "nlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')\n",
    "token = nlp('prices')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "Rv5kWcJ_SGrK",
    "outputId": "cadca765-30e1-47ca-f16d-673d96ccc946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Lemma('monetary_value.n.01.monetary_value'),\n",
       " Lemma('monetary_value.n.01.price'),\n",
       " Lemma('monetary_value.n.01.cost'),\n",
       " Lemma('price.n.02.price'),\n",
       " Lemma('price.n.02.terms'),\n",
       " Lemma('price.n.02.damage'),\n",
       " Lemma('price.n.03.price'),\n",
       " Lemma('price.n.03.cost'),\n",
       " Lemma('price.n.03.toll'),\n",
       " Lemma('price.n.04.price'),\n",
       " Lemma('price.n.05.price'),\n",
       " Lemma('price.n.06.price'),\n",
       " Lemma('price.n.07.Price'),\n",
       " Lemma('price.n.07.Leontyne_Price'),\n",
       " Lemma('price.n.07.Mary_Leontyne_Price')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wordnet object link spacy token with nltk wordnet interface by giving acces to\n",
    "token._.wordnet.synsets()\n",
    "print(\"===========\\n\")\n",
    "token._.wordnet.lemmas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NKZVoJJCSJAW",
    "outputId": "2d71d041-7db1-486b-8682-c7650ab9bc20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book_keeping',\n",
       " 'numismatics',\n",
       " 'betting',\n",
       " 'banking',\n",
       " 'insurance',\n",
       " 'racing',\n",
       " 'social',\n",
       " 'money',\n",
       " 'finance',\n",
       " 'post',\n",
       " 'law',\n",
       " 'commerce',\n",
       " 'enterprise',\n",
       " 'telegraphy',\n",
       " 'mathematics',\n",
       " 'industry',\n",
       " 'economy',\n",
       " 'tax',\n",
       " 'free_time',\n",
       " 'jewellery',\n",
       " 'statistics',\n",
       " 'exchange',\n",
       " 'buildings',\n",
       " 'diplomacy',\n",
       " 'book_keeping',\n",
       " 'factotum',\n",
       " 'agriculture',\n",
       " 'electrotechnology',\n",
       " 'numismatics',\n",
       " 'person',\n",
       " 'telephony',\n",
       " 'metrology',\n",
       " 'politics',\n",
       " 'betting',\n",
       " 'banking',\n",
       " 'sociology',\n",
       " 'insurance',\n",
       " 'racing',\n",
       " 'publishing',\n",
       " 'social',\n",
       " 'money',\n",
       " 'card',\n",
       " 'finance',\n",
       " 'post',\n",
       " 'law',\n",
       " 'topography',\n",
       " 'tourism',\n",
       " 'commerce',\n",
       " 'philology',\n",
       " 'telegraphy',\n",
       " 'enterprise',\n",
       " 'mathematics',\n",
       " 'time_period',\n",
       " 'town_planning',\n",
       " 'animal_husbandry',\n",
       " 'pure_science',\n",
       " 'computer_science',\n",
       " 'economy',\n",
       " 'industry',\n",
       " 'tax',\n",
       " 'quality',\n",
       " 'free_time',\n",
       " 'philately',\n",
       " 'railway',\n",
       " 'jewellery',\n",
       " 'telecommunication',\n",
       " 'statistics',\n",
       " 'exchange',\n",
       " 'economy',\n",
       " 'music']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And automatically tags with wordnet domains\n",
    "token._.wordnet.wordnet_domains()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2xXVtBdqSOwg"
   },
   "source": [
    "Now we choose the subset of domains that are relevant and ignore th erest, See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-o2oLzrwSLa5"
   },
   "outputs": [],
   "source": [
    "# spaCy WordNet lets you find synonyms by domain of interest for example economy\n",
    "sentence = nlp('I want to withdraw 5,000 rupees')\n",
    "economy_domains = ['finance', 'banking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fUrTgMpSSD4"
   },
   "outputs": [],
   "source": [
    "token_with_synsets = [(token, token._.wordnet.wordnet_synsets_for_domain(economy_domains)) for token in sentence]\n",
    "enriched_sentence = []  # empty list to populate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "S44PhY49SUz6",
    "outputId": "e8e17497-b572-4701-cb97-49e5483a6a12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I (need|want|require) to (take_out|draw_off|draw|withdraw) 5,000 rupees\n"
     ]
    }
   ],
   "source": [
    "for token, synsets in token_with_synsets:\n",
    "    \n",
    "    if not synsets:\n",
    "        enriched_sentence.append(token.text)\n",
    "        \n",
    "    else:\n",
    "        lemmas_for_synset = {lemma for s in synsets for lemma in s.lemma_names()}\n",
    "        enriched_sentence.append('({})'.format('|'.join(lemmas_for_synset)))\n",
    "        \n",
    "print(' '.join(enriched_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AW4DEZKqSeKZ"
   },
   "source": [
    "## Functionize above and apply\n",
    "\n",
    "Below I will wrap above code logic into two functions (one for outputting domains identified, second for building the enhanced sentence).\n",
    "\n",
    "More generally, it is good programming practice to *functionize* anything that'll need to be invoked multiple times. \n",
    "\n",
    "Let us examine in which all domains the word 'course' occurs. Best to input plural form of the word.\n",
    "\n",
    "Behold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3li5e_ySb76"
   },
   "outputs": [],
   "source": [
    "# func 1 to yield possible domains\n",
    "def yield_poss_domains(focal_token):\n",
    "    \n",
    "    # nlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')\n",
    "    token = nlp(focal_token)[0]; token\n",
    "    \n",
    "    poss_domain_list = token._.wordnet.wordnet_domains()\n",
    "    return(poss_domain_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Ytdk-SnKSjT-",
    "outputId": "89ccfcaf-75d3-4930-effc-eb4c8887ea19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['social', 'school', 'pedagogy', 'tennis', 'university', 'golf', 'post', 'theology', 'philosophy', 'social', 'time_period', 'occultism', 'aviation', 'psychology', 'psychological_features', 'psychoanalysis', 'astronautics', 'factotum', 'astronomy', 'architecture', 'electrotechnology', 'fencing', 'mechanics', 'rowing', 'meteorology', 'physics', 'metrology', 'betting', 'skiing', 'nautical', 'engineering', 'skating', 'racing', 'geometry', 'astrology', 'baseball', 'football', 'topography', 'tourism', 'drawing', 'telegraphy', 'time_period', 'tv', 'pure_science', 'aviation', 'electricity', 'bowling', 'vehicles', 'transport', 'atomic_physic', 'optics', 'archaeology', 'quality', 'electronics', 'soccer', 'sport', 'military', 'telecommunication', 'oceanography', 'table_tennis', 'golf', 'radio', 'earth', 'cycling', 'artisanship', 'university', 'school', 'pedagogy', 'gastronomy', 'buildings', 'architecture', 'racing', 'sport', 'play', 'golf', 'vehicles']\n"
     ]
    }
   ],
   "source": [
    "# test-drive func above\n",
    "domain_list = yield_poss_domains('courses')\n",
    "print(domain_list)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsAQhDrBSl_z"
   },
   "outputs": [],
   "source": [
    "# func 2 to take in list of domains & output enhanced sentence\n",
    "def domain_2_enhSent(domains_list, sentence):    \n",
    "    \n",
    "    token_with_synsets = [(token, token._.wordnet.wordnet_synsets_for_domain(domains_list)) for token in sentence]\n",
    "    enriched_sentence = []  # empty list to populate\n",
    "    \n",
    "    for token, synsets in token_with_synsets:\n",
    "        \n",
    "        if not synsets:\n",
    "            enriched_sentence.append(token.text)\n",
    "            \n",
    "        else:\n",
    "            lemmas_for_synset = {lemma for s in synsets for lemma in s.lemma_names()}\n",
    "            enriched_sentence.append('({})'.format('|'.join(lemmas_for_synset)))\n",
    "            \n",
    "    enhSent = ' '.join(enriched_sentence)\n",
    "    return(enhSent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "GjgLtsitStZH",
    "outputId": "73042ca3-4ff6-400c-f184-b4195fcae692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MLBM (course_of_instruction|grade|form|course_of_study|course|class) (learn|teach|instruct) at ISB (be|make_up|comprise|represent|constitute) broad - based and (big|large) - (painting|film|image|motion_picture|motion-picture_show|icon|picture_show|flick|ikon|moving_picture|pic|picture|movie|moving-picture_show) in (reach|scope|ambit|compass|range|orbit) .\n"
     ]
    }
   ],
   "source": [
    "# test-drive above\n",
    "domains_list = ['school', 'pedagogy', 'university']\n",
    "sent0 = nlp('The MLBM course taught at ISB is broad-based and big-picture in scope.')\n",
    "enh_sent = domain_2_enhSent(domains_list, sent0)\n",
    "print(enh_sent)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z3Z5sWqnSzFC"
   },
   "source": [
    "That's it from me for now. Back to the Slides.\n",
    "\n",
    "Voleti.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "nltk & spacy exploration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
