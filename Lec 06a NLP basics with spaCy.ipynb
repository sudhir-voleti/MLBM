{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Intro with Spacy\n",
    "\n",
    "We'll see a few basic NLP ops in this notebook. Specifically:<p>\n",
    "\n",
    "- Parts-of-Speech tagging or POSTagging <p>\n",
    "\n",
    "- Chunking Ops for Phrase Detection<p>\n",
    "\n",
    "- Named Entity Recognition or NER<p>\n",
    "\n",
    "I will deal with syntactic dependency parsing in a separate notebook tough we'll debut the concept here. \n",
    "\n",
    "At some point, Q will arise \"So what all can spacy do?\" See below.\n",
    "    \n",
    "https://spacy.io/usage/spacy-101#features\n",
    "\n",
    "![spacy%20functionality%20tbl.png](attachment:spacy%20functionality%20tbl.png)\n",
    "\n",
    "Let's begin, as always, with the setup chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup chunk\n",
    "import spacy\n",
    "\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POSTagging for NLP\n",
    "\n",
    "English text can roughly be divided into “sentences” which are composed of individual *words*, each of which has a function in expressing the meaning of the sentence. \n",
    "\n",
    "The function of a word in a sentence is called its “Part of Speech”—i.e., a word functions as a noun, a verb, an adjective, etc.\n",
    "\n",
    "Of course, the “part of speech” of a word isn’t a property of the word itself. \n",
    "\n",
    "We know this because a single “word” can function as two different parts of speech (due to *polysemy*). \n",
    "\n",
    "For instance, consider 2 sentences:\n",
    "\n",
    "> I love cheese.\n",
    "\n",
    "versus \n",
    "\n",
    "> Love is a battlefield.    \n",
    "\n",
    "No wonder then that it's hard for computers to accurately determine a word's POS in a sentence. (It’s difficult sometimes even for humans to do this.) \n",
    "\n",
    "But NLP procedures do their best, training on massive corpora.\n",
    "\n",
    "Let's start with some dummy examples and then head towards real world examples. Behold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was when I bought my first real six-string. \n",
      "\n",
      "It  ==>  PRON\n",
      "was  ==>  VERB\n",
      "when  ==>  ADV\n",
      "I  ==>  PRON\n",
      "bought  ==>  VERB\n",
      "my  ==>  DET\n",
      "first  ==>  ADJ\n",
      "real  ==>  ADJ\n",
      "six  ==>  NUM\n",
      "-  ==>  PUNCT\n",
      "string  ==>  NOUN\n",
      ".  ==>  PUNCT\n"
     ]
    }
   ],
   "source": [
    "# sample sentence\n",
    "sent0 = \"It was when I bought my first real six-string.\"\n",
    "print(sent0, \"\\n\")\n",
    "\n",
    "# annotate the sentence with spaCy's nlp()\n",
    "ann_sent0 = nlp(sent0)\n",
    "\n",
    "# print the POSTag results\n",
    "for token in ann_sent0:\n",
    "    print(token.text, \" ==> \", token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we preserve *everything* including punctuations (dots, commas, hypohens) and throw out nothing. \n",
    "\n",
    "Very unlike the bag-of-words (BOW) model we did in MKTR wherein we discarded stopwords, upper-case, punctuation etc.\n",
    "\n",
    "### Code a POSTag function\n",
    "\n",
    "Below I code a func to display: <p>\n",
    "\n",
    "- the token itself<p>\n",
    " \n",
    "- it's POSTag, of course <p>\n",
    "\n",
    "- it's **lemma** (i.e. root form of the word. E.g., 'went', 'gone', 'going' all become ==> 'go').<p>\n",
    "\n",
    "- it's **syntactic dependency** (how each token relates to others in the sentcne - will do later)<p>\n",
    "\n",
    "Behold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>postag</th>\n",
       "      <th>depcy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald</td>\n",
       "      <td>Donald</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump</td>\n",
       "      <td>Trump</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>controversial</td>\n",
       "      <td>controversial</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>American</td>\n",
       "      <td>american</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>President</td>\n",
       "      <td>President</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>attr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text          lemma postag     depcy\n",
       "0         Donald         Donald  PROPN  compound\n",
       "1          Trump          Trump  PROPN     nsubj\n",
       "2             is             be   VERB      ROOT\n",
       "3              a              a    DET       det\n",
       "4  controversial  controversial    ADJ      amod\n",
       "5       American       american    ADJ      amod\n",
       "6      President      President  PROPN      attr"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# routine to display sentence as DF postags\n",
    "def token_attrib(sent0):\n",
    "\tdoc = nlp(sent0)\n",
    "\n",
    "\ttext=[]\n",
    "\tlemma=[]\n",
    "\tpostag=[]\n",
    "\tdepcy=[]\n",
    "\n",
    "\tfor token in doc:\n",
    "\t\ttext.append(token.text)\n",
    "\t\tlemma.append(token.lemma_)\n",
    "\t\tpostag.append(token.pos_)\n",
    "\t\tdepcy.append(token.dep_)\n",
    "\n",
    "\ttest_df = pd.DataFrame({'text':text, 'lemma':lemma, 'postag':postag, 'depcy':depcy})\n",
    "\treturn(test_df)\n",
    "\n",
    "# test-drive above func on test data\n",
    "sent0 = \"Donald Trump is a controversial American President\"\n",
    "test_df = token_attrib(sent0)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on the POSTAg colm above. Time to refresh our Eng grammer (Wren & Martin, anyone?).\n",
    "\n",
    "Pls open the *Penn Treebank* to see what the POStags mean.\n",
    "\n",
    "Quick Quiz: Which is the *most important* POSTag in a sentence? W/o which no sentence can grammatically form?\n",
    "  \n",
    "Now let's look at a slightly more complex sentence than the simple one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>postag</th>\n",
       "      <th>depcy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Universal</td>\n",
       "      <td>Universal</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Studios</td>\n",
       "      <td>Studios</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will</td>\n",
       "      <td>will</td>\n",
       "      <td>VERB</td>\n",
       "      <td>aux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not</td>\n",
       "      <td>not</td>\n",
       "      <td>ADV</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>franchise</td>\n",
       "      <td>franchise</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>copyrighted</td>\n",
       "      <td>copyright</td>\n",
       "      <td>VERB</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>content</td>\n",
       "      <td>content</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>dobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>regardless</td>\n",
       "      <td>regardless</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>prep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>what</td>\n",
       "      <td>what</td>\n",
       "      <td>PRON</td>\n",
       "      <td>dobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>press</td>\n",
       "      <td>press</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>speculates</td>\n",
       "      <td>speculate</td>\n",
       "      <td>VERB</td>\n",
       "      <td>pcomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           text       lemma postag     depcy\n",
       "0     Universal   Universal  PROPN  compound\n",
       "1       Studios     Studios  PROPN     nsubj\n",
       "2          will        will   VERB       aux\n",
       "3           not         not    ADV       neg\n",
       "4     franchise   franchise   VERB      ROOT\n",
       "5   copyrighted   copyright   VERB      amod\n",
       "6       content     content   NOUN      dobj\n",
       "7    regardless  regardless    ADV    advmod\n",
       "8            of          of    ADP      prep\n",
       "9          what        what   PRON      dobj\n",
       "10          the         the    DET       det\n",
       "11        press       press   NOUN     nsubj\n",
       "12   speculates   speculate   VERB     pcomp\n",
       "13            .           .  PUNCT     punct"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly more complex sentence\n",
    "sent0 = \"Universal Studios will not franchise copyrighted content regardless of what the press speculates.\"\n",
    "\n",
    "# POStag it and display DF result\n",
    "token_attrib(sent0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly from the above example, a sentence can have multiple nouns and verbs.\n",
    "\n",
    "However, seems like it can have only one ROOT verb. Which is central to the sentence.\n",
    "\n",
    "This below is an example of a 2-clause sentence. In which clause do you think the ROOT verb will lie? Behold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>postag</th>\n",
       "      <th>depcy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Because</td>\n",
       "      <td>because</td>\n",
       "      <td>ADP</td>\n",
       "      <td>mark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>went</td>\n",
       "      <td>go</td>\n",
       "      <td>VERB</td>\n",
       "      <td>advcl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>early</td>\n",
       "      <td>early</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I</td>\n",
       "      <td>-PRON-</td>\n",
       "      <td>PRON</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>saw</td>\n",
       "      <td>see</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>dobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text    lemma postag   depcy\n",
       "0  Because  because    ADP    mark\n",
       "1        I   -PRON-   PRON   nsubj\n",
       "2     went       go   VERB   advcl\n",
       "3    early    early    ADV  advmod\n",
       "4        ,        ,  PUNCT   punct\n",
       "5        I   -PRON-   PRON   nsubj\n",
       "6      saw      see   VERB    ROOT\n",
       "7      the      the    DET     det\n",
       "8  sunrise  sunrise   NOUN    dobj\n",
       "9        .        .  PUNCT   punct"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A 2-clause sentence\n",
    "sent0=\"Because I went early, I saw the sunrise.\"\n",
    "\n",
    "token_attrib(sent0)  # display anotation as a DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clauses are sort of mini-sentences. Those which can stand alone as complete sentences by themselves are 'independent cluases'. E.g., \"I saw the sunrise.\"\n",
    "\n",
    "A dependent clause makes some sort of sense but is not a complete sentence byu itself. E.g., from above: \"Because I went early\"\n",
    "\n",
    "Note that the ROOT verb always shows up in the independent clause only.\n",
    "\n",
    "In fact, if the word ROOT rings any bells (ROOT nodes in d-trees, remember?), we can:<p>\n",
    "\n",
    "- **parse** the sentence's syntax into a tree like structure (the parse-tree)<p>\n",
    "\n",
    "- starting with the root verb as the root node at the top<p> \n",
    "\n",
    "- and [progressively mapping (syntactic) dependencies with other tokens in the sentence.<p>\n",
    "\n",
    "### A Dependency Parse Tree Illustration\n",
    "\n",
    "To do that,let me first code a small helper routine that will map the parse-tree out for us. Behold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            is                       \n",
      "  __________|________                 \n",
      " |  Trump        President           \n",
      " |    |      ________|__________      \n",
      " .  Donald  a  controversial American\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def func to display depcy tree. Note recursive struc!!\n",
    "from nltk import Tree\n",
    "def to_nltk_tree(node):\n",
    "\tif node.n_lefts + node.n_rights > 0:\n",
    "\t\treturn Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "\telse:\n",
    "\t\treturn node.orth_\n",
    "\n",
    "# print tree for seq of sents if needed\n",
    "sent0 = \"Donald Trump is a controversial American President.\" \n",
    "sent = nlp(sent0)\n",
    "[to_nltk_tree(sent.root).pretty_print() for sent in sent.sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the classic tree structure above. Root node is typically always the ROOT verb, in this case 'is'. From the Root node, the dependencies start. \n",
    "\n",
    "Not hard to see from above that the dependency parse tree automatically shows us coherent 'chunks' of phrases, and even clauses if we put our mind to it.\n",
    "\n",
    "Let me head quickly to the slides to demo what I mean. \n",
    "\n",
    "We'll dig into the Syntactic dependency parsing further down.\n",
    "\n",
    "For now, let me turn my attention to more basic if mundane stuff starting with token-chunks called *phrases*.       \n",
    "\n",
    "## Chunking Ops with spaCy\n",
    "\n",
    "spaCy defines a *chunk* entity that detects consecutive groups tokens that coukld likely be NPs or VPs. spaCy is smart like that.\n",
    "\n",
    "Behold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               chText chRootText chRootDep chRootHead\n",
      "0                        Donald Trump      Trump     nsubj         is\n",
      "1  a controversial American President  President      attr         is\n"
     ]
    }
   ],
   "source": [
    "## define a func to extract & display chunking ops\n",
    "def chunkAttrib(sent0):\n",
    "\n",
    "\tdoc = nlp(sent0)\n",
    "\tchunk1 = [(chunk.text, chunk.root.text, chunk.root.dep_, chunk.root.head.text) for chunk in doc.noun_chunks]\n",
    "    \n",
    "\tout_df1 = pd.DataFrame(chunk1, columns = ['chText', 'chRootText', 'chRootDep', 'chRootHead'])\n",
    "\treturn(out_df1)\n",
    "\n",
    "# test-drive above func\n",
    "sent0 = \"Donald Trump is a controversial American President.\"\n",
    "chunk_df = chunkAttrib(sent0)  # 0.01 secs\n",
    "print(chunk_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example a rule could be that whenever any of a NNP, NNPS, ADJ, DET or xyz occur consecutively together in a sentence, detect such pattern and extract it as a 'noun phrase' chunk.\n",
    "\n",
    "One could do similar for verb phrases too.\n",
    "\n",
    "## Named Entity Recognition NER with spaCy\n",
    "\n",
    "What kind of named entities (people, dates and times, money etc) might businesses be interested in? \n",
    "\n",
    "What are the types that standard NER in spaCy supports recognition for?\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1000/1*qQggIPMugLcy-ndJ8X_aAA.png\" alt=\"Alt text that describes the graphic\" title=\"Named Entities in Spacy\" />\n",
    "\n",
    "the *token.ents* command run on the annotated document in spaCy is for NER. See below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_text</th>\n",
       "      <th>ent_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>European</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$5.1 billion</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ent_text ent_label\n",
       "0      European      NORP\n",
       "1        Google       ORG\n",
       "2  $5.1 billion     MONEY\n",
       "3     Wednesday      DATE"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying entity detection in one sample sentence first\n",
    "doc = nlp('European authorities fined Google a record $5.1 billion on Wednesday for abusing its power in the mobile phone market and ordered the company to alter its practices')\n",
    "print(doc)\n",
    "\n",
    "# Note the .ents type\n",
    "ent_text = [X.text for X in doc.ents]\n",
    "ent_label = [X.label_ for X in doc.ents]\n",
    "\n",
    "# store and sisplay as panda DF\n",
    "ent_df = pd.DataFrame({'ent_text':ent_text, 'ent_label':ent_label})\n",
    "ent_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chances are many entities will be multi-token chunks (n-grams) like that '$5.1 billion' wala entity above. \n",
    "\n",
    "How then to ID where the entity chunk begins and where it ends?\n",
    "\n",
    "### Spacy's NER with BILOU chunking\n",
    "\n",
    "The old IOB scheme (Inside-Outside-Beginning) for multi-token chunk identification has now given way to an expanded version called BILOU (see below). \n",
    "\n",
    "<img src = \"https://cdn-images-1.medium.com/max/800/1*_sYTlDj2p_p-pcSRK25h-Q.png\" alt=\"Alt text that describes the graphic\" title=\"BILOU for Named Entities in Spacy\" />\n",
    "\n",
    "We will invoke both IOB and BILOU in spacy to supplement NER info. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_token</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>European</td>\n",
       "      <td>B</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>authorities</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fined</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>record</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>$</td>\n",
       "      <td>B</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.1</td>\n",
       "      <td>I</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>billion</td>\n",
       "      <td>I</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>on</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>B</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>for</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abusing</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>its</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>power</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mobile</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>phone</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>market</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>and</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ordered</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>company</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>alter</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>its</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>practices</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ent_token ent_iob ent_type\n",
       "0      European       B     NORP\n",
       "1   authorities       O         \n",
       "2         fined       O         \n",
       "3        Google       B      ORG\n",
       "4             a       O         \n",
       "5        record       O         \n",
       "6             $       B    MONEY\n",
       "7           5.1       I    MONEY\n",
       "8       billion       I    MONEY\n",
       "9            on       O         \n",
       "10    Wednesday       B     DATE\n",
       "11          for       O         \n",
       "12      abusing       O         \n",
       "13          its       O         \n",
       "14        power       O         \n",
       "15           in       O         \n",
       "16          the       O         \n",
       "17       mobile       O         \n",
       "18        phone       O         \n",
       "19       market       O         \n",
       "20          and       O         \n",
       "21      ordered       O         \n",
       "22          the       O         \n",
       "23      company       O         \n",
       "24           to       O         \n",
       "25        alter       O         \n",
       "26          its       O         \n",
       "27    practices       O         "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NER with IOB chunking\n",
    "# using X.ent_iob and X.ent_type\n",
    "ent_token = [X for X in doc]\n",
    "ent_iob = [X.ent_iob_ for X in doc]  # for IOB scheme\n",
    "ent_type = [X.ent_type_ for X in doc]\n",
    "\n",
    "# store and display as DF\n",
    "ent_chunk = pd.DataFrame({'ent_token':ent_token, 'ent_iob':ent_iob, 'ent_type':ent_type})\n",
    "ent_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Too long and messy. And all just for one sentence. The 'O' tags are uninformative anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ent_token</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>European</td>\n",
       "      <td>B</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$</td>\n",
       "      <td>B</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>I</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>billion</td>\n",
       "      <td>I</td>\n",
       "      <td>MONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>B</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ent_token ent_iob ent_type\n",
       "0   European       B     NORP\n",
       "1     Google       B      ORG\n",
       "2          $       B    MONEY\n",
       "3        5.1       I    MONEY\n",
       "4    billion       I    MONEY\n",
       "5  Wednesday       B     DATE"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cleaning it up a little bit to drop the Os above\n",
    "ent_token = [X for X in doc if X.ent_iob_ != 'O']\n",
    "ent_iob = [X.ent_iob_ for X in doc if X.ent_iob_ != 'O']\n",
    "ent_type = [X.ent_type_ for X in doc if X.ent_iob_ != 'O']\n",
    "\n",
    "ent_chunk = pd.DataFrame({'ent_token':ent_token, 'ent_iob':ent_iob, 'ent_type':ent_type})\n",
    "ent_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpfully, spaCy provides different ways to get a view of and an overview of named entities in text.\n",
    "\n",
    "Below, I import displaCy for one of its display capabilities. \n",
    "\n",
    "### Display NER output with displacy\n",
    "\n",
    "See the use of displacy.render() func below with argument 'jupyter=True'.\n",
    "\n",
    "Behold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Donald Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is a controversial \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " president both in the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and abroad.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## displaCy example\n",
    "from spacy import displacy\n",
    "\n",
    "text = \"Donald Trump is a controversial American president both in the US and abroad.\"\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another, richer  example with more entity types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I went first to \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Africa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " to shoot an elephant on camera. Then I went to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Australia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " to shoot kangaroos. Then to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Dubai\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    the Middle East\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " to ride camels. Then I came to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    India\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " to see the holy cow.</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rendering entities recognized by spacy\n",
    "doc1 = nlp(u'I went first to Africa to shoot an elephant on camera. Then I went to Australia to shoot kangaroos. Then to Dubai in the Middle East to ride camels. Then I came to India to see the holy cow.')\n",
    "\n",
    "displacy.render(doc1, style='ent', jupyter=True) # note 'options'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've dealt only with small, dummy sample stuff. \n",
    "\n",
    "Does spaCy NLP scale to larger real-world datasets? Time to try and find out. \n",
    "\n",
    "## spaCy NLP on a real world dataset (Nokia)\n",
    "\n",
    "The 120 reviews wala corpus from 2013 on the Nokia Lumia smartphone is an old favorite of mine and we've seen this before in MKTR.\n",
    "\n",
    "Let's give it a quick spin here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "120 \n",
      "\n",
      "0.18\n",
      "=======\n",
      "\n",
      "(482, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_ind</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>postag</th>\n",
       "      <th>depcy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b\"I</td>\n",
       "      <td>b\"I</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>have</td>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "      <td>aux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>had</td>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>amod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>phones</td>\n",
       "      <td>phone</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>dobj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>where</td>\n",
       "      <td>where</td>\n",
       "      <td>ADV</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>det</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>screens</td>\n",
       "      <td>screen</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sent_ind     text    lemma postag   depcy\n",
       "0        0      b\"I      b\"I  PROPN   nsubj\n",
       "1        0     have     have   VERB     aux\n",
       "2        0      had     have   VERB    ROOT\n",
       "3        0  Samsung  Samsung  PROPN    amod\n",
       "4        0   phones    phone   NOUN    dobj\n",
       "5        0        ,        ,  PUNCT   punct\n",
       "6        0    where    where    ADV  advmod\n",
       "7        0      the      the    DET     det\n",
       "8        0  screens   screen   NOUN   nsubj"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test-drive NLP funcs on Nokia dataset\n",
    "import urllib.request\n",
    "url = \"https://raw.githubusercontent.com/sudhir-voleti/sample-data-sets/master/text%20analysis%20data/amazon%20nokia%20lumia%20reviews.txt\"\n",
    "nokia = urllib.request.urlopen(url).readlines()\n",
    "\n",
    "print(type(nokia), \"\\n\")\n",
    "print(len(nokia), \"\\n\")\n",
    "\n",
    "# try on 1 doc in nokia dataset\n",
    "import time\n",
    "from nltk import sent_tokenize\n",
    "nokia1 = str(nokia[0]).strip('[]')  # make string\n",
    "nokia1_sents = sent_tokenize(nokia1)  # sent tokenization\n",
    "\n",
    "# define empty DF to populate\n",
    "poso_df = pd.DataFrame(columns=['sent_ind', 'text', 'lemma', 'postag', 'depcy'])\n",
    "\n",
    "t1 = time.time()\n",
    "for i in range(len(nokia1_sents)):\n",
    "    \n",
    "    sent0 = nokia1_sents[i]\n",
    "    df0 = token_attrib(sent0)\n",
    "    df0.insert(0, \"sent_ind\", i)\n",
    "    poso_df = poso_df.append(df0)\n",
    "    \n",
    "t2 = time.time()\n",
    "print(round(t2-t1,2))    # 0.25 secs\n",
    "print(\"=======\\n\")\n",
    "print(poso_df.shape)  # what is size of the DF?\n",
    "poso_df.iloc[0:9,:]  # view a few rows of the DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was just the first review. Took a fraction of a second.\n",
    "\n",
    "### NER on Nokia data\n",
    "\n",
    "Time now to run spaCy`s famed NER on Nokia. The entire 120 review corpus this time. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4001127000000224 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_ind</th>\n",
       "      <th>token</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>iPhones</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>money.&lt;br</td>\n",
       "      <td>B</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>/&gt;&lt;br</td>\n",
       "      <td>I</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>B</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Drive</td>\n",
       "      <td>I</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Music</td>\n",
       "      <td>I</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>B</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_ind      token ent_iob  ent_type\n",
       "0        0    Samsung       B       ORG\n",
       "1        0    iPhones       B       ORG\n",
       "2        0  money.<br       B    PERSON\n",
       "3        0      /><br       I    PERSON\n",
       "4        0      Nokia       B       GPE\n",
       "5        0      Nokia       B       ORG\n",
       "6        0      Nokia       B       ORG\n",
       "7        0      Drive       I       ORG\n",
       "8        0      Nokia       B       ORG\n",
       "9        0      Music       I       ORG\n",
       "10       0       1500       B  CARDINAL\n",
       "11       0       ESPN       B       ORG"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyze real data - nokia with spacy\n",
    "a0 = [i for i in range(len(nokia))]\n",
    "nokia_str = [str(x).strip('[]') for x in nokia]\n",
    "\n",
    "start_time = time.clock()\n",
    "\n",
    "# dropping 'O' entities & enumerating doc_num \n",
    "nokia_ents = [[(i, X, X.ent_iob_, X.ent_type_) for X in nlp(nokia_str[i]) if X.ent_iob_ != 'O'] for i in a0] # 6.87 secs\n",
    "print(time.clock() - start_time, \"seconds\")  # 5.5 secs\n",
    "\n",
    "# make DF and display\n",
    "nokia_ents_df = pd.DataFrame(columns = ['doc_ind', 'token', 'ent_iob', 'ent_type'])\n",
    "\n",
    "for i in range(len(nokia_ents)):\n",
    "    df0 = pd.DataFrame(nokia_ents[i], columns =['doc_ind', 'token', 'ent_iob', 'ent_type']) \n",
    "    nokia_ents_df = nokia_ents_df.append(df0)\n",
    "    \n",
    "nokia_ents_df.iloc[0:12,:]  # view first 12 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy, eh?\n",
    "\n",
    "Now say, we want to find every mention of organizations ('ORG') in the review corpus. Or persons ('PERSON') or facilities ('FAC') or money. Etc.\n",
    "\n",
    "Then its a simple matter of cleverly using entities to get a superset which we could then further refine.\n",
    "\n",
    "P.S. Of course, the NER in spaCy or elsewhere for that matter isn't perfect and will make errors of both type I and II (i.e. of ommission or commission).\n",
    "\n",
    "See below for an example with the ORG entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_ind</th>\n",
       "      <th>token</th>\n",
       "      <th>ent_iob</th>\n",
       "      <th>ent_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>iPhones</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Drive</td>\n",
       "      <td>I</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Nokia</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Music</td>\n",
       "      <td>I</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>ESPN</td>\n",
       "      <td>B</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_ind    token ent_iob ent_type\n",
       "0        0  Samsung       B      ORG\n",
       "1        0  iPhones       B      ORG\n",
       "5        0    Nokia       B      ORG\n",
       "6        0    Nokia       B      ORG\n",
       "7        0    Drive       I      ORG\n",
       "8        0    Nokia       B      ORG\n",
       "9        0    Music       I      ORG\n",
       "11       0     ESPN       B      ORG"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter above to retain only 'ORG' named entity type\n",
    "new_ent_df = nokia_ents_df[(nokia_ents_df['ent_type'] == 'ORG')]\n",
    "new_ent_df.iloc[:8, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chalo, back to the slides now.\n",
    "\n",
    "What follows is a separate foray into dependency parsing but some Q & A before that.\n",
    "\n",
    "Sudhir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
